{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4105f8",
   "metadata": {},
   "source": [
    "# Interview Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"showcase-raw\"\n",
    "subfolder = \"BHS Baseball /BHS Baseball and Ramblers/STREAM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a982792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ffmpeg ffmpeg-python ffprobe opencv-python mediapipe\n",
    "!pip install opencv-python mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c258a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# import ffmpeg\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde309e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "\n",
    "\n",
    "def create_presigned_url(bucket_name, object_name, expiration=3600):\n",
    "    \"\"\"Generate a presigned URL to share an S3 object\n",
    "\n",
    "    :param bucket_name: string\n",
    "    :param object_name: string\n",
    "    :param expiration: Time in seconds for the presigned URL to remain valid\n",
    "    :return: Presigned URL as string. If error, returns None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a presigned URL for the S3 object\n",
    "    \n",
    "    try:\n",
    "        response = s3_client.generate_presigned_url(ClientMethod='get_object',\n",
    "                                                    Params={'Bucket': bucket_name,\n",
    "                                                            'Key': object_name},\n",
    "                                                    ExpiresIn=expiration)\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    # The response contains the presigned URL\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CONT_DETECTS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba1308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_video_metadata(media_file_path):\n",
    "#     # uses ffprobe command to extract all possible metadata from the media file\n",
    "#     metadata = ffmpeg.probe(media_file_path)[\"streams\"]\n",
    "\n",
    "#     # print()\n",
    "#     # print(\"type(metadata):\\t\", type(metadata))\n",
    "#     # print(\"metadata\")\n",
    "#     # pprint(metadata[0])\n",
    "\n",
    "#     duration = int(float(metadata[0].get(\"duration\", 0)))\n",
    "#     num_frames = int(metadata[0].get(\"nb_frames\", 0))\n",
    "#     frame_rate = int(eval(metadata[0].get(\"avg_frame_rate\", 0)))\n",
    "\n",
    "#     return duration, num_frames, frame_rate\n",
    "\n",
    "\n",
    "# def convert_seconds_to_time(seconds):\n",
    "#     return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24db72d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "VID_OUT = cv2.VideoWriter('output.mp4', fourcc, 20.0, (640, 480))\n",
    "\n",
    "\n",
    "class InterviewDetector():\n",
    "    \n",
    "    def __init__(self, min_confidence=0.5):\n",
    "        self.start = 0\n",
    "        self.end = 0\n",
    "        self.n_cont_detects = 0\n",
    "        self.mp_draw = mp.solutions.drawing_utils\n",
    "        self.face_detector = mp.solutions.face_detection.FaceDetection(\n",
    "            min_confidence)\n",
    "\n",
    "    def find_faces(self, img, frame_num, draw=True):\n",
    "        global NUM_CONT_DETECTS, VID_OUT\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.face_detector.process(img_rgb)\n",
    "        # print(self.results)\n",
    "\n",
    "        bboxs = []\n",
    "        if self.results.detections:\n",
    "            self.n_cont_detects += 1\n",
    "            if (not self.start) and self.n_cont_detects > NUM_CONT_DETECTS:\n",
    "                self.start = frame_num\n",
    "            else:\n",
    "                self.end = frame_num\n",
    "            if self.n_cont_detects > NUM_CONT_DETECTS:\n",
    "                for idx, detection in enumerate(self.results.detections):\n",
    "                    bbox_c = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, ic = img.shape\n",
    "                    bbox = int(bbox_c.xmin * iw), int(bbox_c.ymin * ih), \\\n",
    "                           int(bbox_c.width * iw), int(bbox_c.height * ih)\n",
    "                    bboxs.append([idx, bbox, detection.score])\n",
    "                    if draw:\n",
    "                        img = self.fancy_draw(img, bbox)\n",
    "                        cv2.putText(img, f'{int(detection.score[0] * 100)}%',\n",
    "                                    (bbox[0], bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN,\n",
    "                                    2, (255, 0, 255), 2)\n",
    "                        frame = cv2.resize(img, (640, 480))\n",
    "                        VID_OUT.write(frame)\n",
    "        return img, bboxs\n",
    "\n",
    "    def fancy_draw(self, img, bbox, l=30, t=5, rt=1):\n",
    "        x, y, w, h = bbox\n",
    "        x1, y1 = x + w, y + h\n",
    "        color = (255, 0, 255)\n",
    "\n",
    "        cv2.rectangle(img, bbox, color, rt)\n",
    "        # Top Left  x,y\n",
    "        cv2.line(img, (x, y), (x + l, y), color, t)\n",
    "        cv2.line(img, (x, y), (x, y + l), color, t)\n",
    "        # Top Right  x1,y\n",
    "        cv2.line(img, (x1, y), (x1 - l, y), color, t)\n",
    "        cv2.line(img, (x1, y), (x1, y + l), color, t)\n",
    "        # Bottom Left  x,y1\n",
    "        cv2.line(img, (x, y1), (x + l, y1), color, t)\n",
    "        cv2.line(img, (x, y1), (x, y1 - l), color, t)\n",
    "        # Bottom Right  x1,y1\n",
    "        cv2.line(img, (x1, y1), (x1 - l, y1), color, t)\n",
    "        cv2.line(img, (x1, y1), (x1, y1 - l), color, t)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path):\n",
    "    # read the audio/video file from the command line arguments\n",
    "    # video_path = sys.argv[1]\n",
    "    print()\n",
    "    print('*' * 50)\n",
    "    print(\"video_path:\\t\", video_path)\n",
    "\n",
    "    # # get metadata of the video\n",
    "    # duration, num_frames, frame_rate = get_video_metadata(video_path)\n",
    "    # print()\n",
    "    # print(\"Duration:\\t\", convert_seconds_to_time(duration))\n",
    "    # # print(\"# frames:\\t\", num_frames)\n",
    "    # print(\"Frame rate:\\t\", frame_rate)\n",
    "\n",
    "    # process frame-by-frame\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    p_time = 0\n",
    "    frame_counter = 0\n",
    "\n",
    "    detector = InterviewDetector()\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        img, bboxs = detector.find_faces(img, frame_counter)\n",
    "        # print(bboxs)\n",
    "\n",
    "        frame_counter += 1\n",
    "        c_time = time.time()\n",
    "        fps = 1 / (c_time - p_time)\n",
    "        p_time = c_time\n",
    "        # cv2.putText(img, f'FPS: {int(fps)}', (20, 70),\n",
    "        #             cv2.FONT_HERSHEY_PLAIN, 3, (0, 255, 0), 2)\n",
    "        # cv2.imshow(\"Image\", img)\n",
    "        # cv2.waitKey(1)\n",
    "\n",
    "    print()\n",
    "    print(\"frame_counter:\\t\", frame_counter)\n",
    "    print(\"Start frame #:\\t\", detector.start)\n",
    "    print(\"End frame #:\\t\", detector.end)\n",
    "    # print(\"Interview start time (s):\\t\", convert_seconds_to_time(\n",
    "    #     int(detector.start / frame_rate)))\n",
    "    # print(\"Interview end time (s):\\t\\t\", convert_seconds_to_time(\n",
    "    #     int(detector.end / frame_rate)))\n",
    "    \n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5816d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = s3_client.list_objects(Bucket=bucket_name, Prefix=subfolder)['Contents']\n",
    "\n",
    "for i, f in enumerate(contents):\n",
    "    # print(\"f['Key']:\\t\", f['Key'])\n",
    "    # if i > 8: continue\n",
    "    url = create_presigned_url(bucket_name, f['Key'])\n",
    "    main(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap.release()\n",
    "VID_OUT.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f52f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file('output.mp4', bucket_name, 'output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456179d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
